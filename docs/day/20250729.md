>一、核心目标
离线数仓的设计需满足以下目标：

数据整合：将分散在业务系统（如 MySQL、日志、埋点数据等）的异构数据统一存储，消除数据孤岛。
数据清洗与规范：处理脏数据（缺失、重复、错误），统一数据格式和维度，保证数据质量。
高效查询与分析：支持复杂的多维度分析、聚合计算，满足报表、大屏、业务决策等需求。
可扩展性：随业务增长，能低成本扩展存储和计算能力。
可追溯性：记录数据血缘（数据来源、处理过程），便于问题排查和审计。
二、数据分层设计（核心思路）
离线数仓的分层是为了将数据处理过程拆解为 “逐步净化、抽象” 的阶段，降低复杂度。经典分层如下（不同场景可能调整）：
1. 原始数据层（ODS，Operational Data Store）
   作用：存放原始数据，不做任何清洗或转换，保留数据原貌，作为数据溯源的依据。
   数据来源：
   业务数据库（MySQL、Oracle 等）的全量 / 增量同步数据（如通过 Sqoop、DataX）。
   日志数据（用户行为日志、系统日志等，如通过 Flume 采集）。
   第三方数据（API 接口数据、合作方数据等）。
   存储格式：通常用文本文件（如 CSV）、Parquet、ORC 等，结合 HDFS 或对象存储（如 S3）存储。
   特点：数据量大、格式异构、保留原始字段（包括冗余字段）。
2. 数据仓库层（DW，Data Warehouse）
   DW 层是数仓的核心，负责数据的清洗、转换、整合，按 “主题” 组织数据（如用户主题、订单主题、商品主题）。进一步细分为：
   （1）明细层（DWD，Data Warehouse Detail）
   作用：对 ODS 层数据进行清洗（去重、补全缺失值、格式转换等），并按业务实体拆分明细数据，形成结构化的明细数据。
   处理逻辑：
   去除重复数据（如同一用户的重复行为日志）。
   补全缺失值（如用默认值填充空字段）。
   格式标准化（如日期统一为 “yyyy-MM-dd”，金额统一单位）。
   拆分复杂字段（如将 JSON 格式的日志字段拆分为独立列）。
   存储：常用 Parquet/ORC（列存格式，压缩率高，适合分析），按时间 / 维度分区（如按天分区）。
   （2）汇总层（DWS，Data Warehouse Summary）
   作用：对 DWD 层的明细数据按业务需求进行轻度汇总，减少下游计算压力。
   汇总维度：按时间（如日 / 周 / 月）、用户（如新 / 老用户）、商品（如品类）等维度汇总。
   示例：
   每日用户活跃数（按日期 + 地区汇总）。
   商品的日销量、周销量（按商品 ID + 时间汇总）。
   特点：数据量比 DWD 小，支持快速查询，作为 ADS 层的直接数据源。
3. 应用数据层（ADS，Application Data Service）
   作用：面向具体业务场景（如报表、dashboard、数据大屏），提供最终的统计结果数据。
   数据来源：从 DWS 层或 DWD 层进一步汇总计算，直接满足业务需求。
   示例：
   月度销售报表数据（销售额、利润率、Top10 商品）。
   用户留存率、转化率等运营指标数据。
   存储：可存于 Hive（供 BI 工具查询）、MySQL（供业务系统调用）或 ClickHouse（实时查询）。
   三、维度建模（核心方法论）
   离线数仓通常采用维度建模（区别于传统的 ER 建模），以 “事实表 + 维度表” 的形式组织数据，便于业务人员理解和分析。
1. 事实表（Fact Table）
   记录业务过程中的 “度量值”（如订单金额、销量、点击量），是分析的核心数据。
   类型：
   事务事实表：记录单次业务事件（如订单表、支付表）。
   周期快照事实表：记录某一时刻的状态（如每日用户余额表）。
   累积快照事实表：记录业务全生命周期（如订单从创建到支付、发货、完成的全流程时间）。
2. 维度表（Dimension Table）
   描述事实表中的 “维度属性”（如用户维度、商品维度、时间维度），用于过滤、分组和标签化。
   示例：
   用户维度表：用户 ID、姓名、性别、注册时间、地区等。
   商品维度表：商品 ID、名称、品类、价格、上架时间等。
   时间维度表：日期、星期、月份、季度、是否节假日等（便于按时间维度分析）。
3. 星型模型与雪花模型
   星型模型：一个事实表关联多个维度表，维度表之间无关联，结构简单，查询效率高（数仓常用）。
   雪花模型：维度表可进一步拆分（如地区维度拆分为国家、省、市表），结构更规范但查询关联复杂，较少用。
   四、ETL 流程设计
   ETL（Extract-Transform-Load）是离线数仓的数据处理核心流程，负责将数据从 ODS 层逐步转换到 DW 层和 ADS 层。
1. Extract（抽取）
   从源系统抽取数据到 ODS 层，需考虑：
   全量抽取：首次同步或周期性全量备份（如每天凌晨全量同步 MySQL 表）。
   增量抽取：仅同步新增 / 变化的数据（如通过 binlog 日志、时间戳、自增 ID 实现）。
   抽取工具：Sqoop（关系型数据库→HDFS）、DataX（多源数据同步）、Flume（日志采集）、Flink CDC（实时捕获变更）等。
2. Transform（转换）
   核心步骤，包括清洗、过滤、聚合、关联等，主要在 DWD 和 DWS 层实现。
   工具：Hive SQL（批处理）、Spark SQL（分布式计算，效率更高）、Flink（支持批流一体）。
   转换规则需文档化，确保可复用和维护（如通过配置文件或 SQL 脚本管理）。
3. Load（加载）
   将转换后的数据加载到目标层（如 DWD、DWS、ADS），需考虑：
   分区加载：按时间（如 dt='2023-10-01'）或维度分区，便于查询过滤和数据生命周期管理（如删除过期数据）。
   覆盖 / 追加策略：全量数据通常覆盖，增量数据通常追加。
   加载工具：Hive（直接写入分区表）、Spark（写入 Parquet 文件到 HDFS）等。
   五、数据生命周期管理
   离线数仓数据量大，需合理管理数据生命周期，降低存储成本：

冷热数据分离：
热数据（近 3 个月）：存于高性能存储（如 HDFS SSD 节点），保证查询速度。
冷数据（3 个月以上）：迁移到低成本存储（如对象存储、磁带库），仅保留必要的汇总数据。
数据过期删除：通过脚本定期删除超过保留期的原始数据（如 ODS 层数据保留 1 年，DWD 层保留 3 年）。
分区管理：按时间分区（如按天），便于批量删除旧分区。
六、数据治理
确保数据质量和可用性，包括：

数据血缘：记录数据的来源和处理过程（如通过 Atlas、Hive 的 Lineage 功能），便于追溯问题。
元数据管理：管理表结构、字段含义、分区信息、ETL 任务依赖等（工具：Amundsen、Metacat）。
数据质量监控：
监控指标：数据量波动（如突然减少 50%）、空值率、重复率、业务规则校验（如订单金额不能为负）。
工具：Griffin、自定义脚本（定时跑校验 SQL，异常时告警）。
权限管理：按角色分配表 / 字段的查询权限（如 Hive 的 Sentry、Ranger），保护敏感数据（如用户手机号、身份证号需脱敏）。